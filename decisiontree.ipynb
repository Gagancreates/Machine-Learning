{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e261aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will be building a decision tree to classify whether a student will pass an exam based on attendance and study hours per week\n",
    "import numpy as np\n",
    "\n",
    "#here is the synthetic dataset that we will be using for this\n",
    "\n",
    "# Features: [Study Hours per Week, Attendance %]\n",
    "# Labels: 0 = Fail, 1 = Pass\n",
    "\n",
    "X = np.array([\n",
    "    [2, 60],   # studied little, low attendance → Fail\n",
    "    [3, 65],   # little study, low attendance → Fail\n",
    "    [5, 70],   # average study, average attendance → Fail\n",
    "    [7, 80],   # good study, good attendance → Pass\n",
    "    [8, 85],   # high study, good attendance → Pass\n",
    "    [10, 90],  # very high study, excellent attendance → Pass\n",
    "])\n",
    "y = np.array([0, 0, 0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5b887b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we can see we can split the example as something like, if study hours<=6, then fail\n",
    "#but we have to do it mathematically as our model should learn to split the features here\n",
    "#now lets implement it\n",
    "\n",
    "# lets define gini impurity\n",
    "\n",
    "def gini_from_counts(counts):    #this is when we have the count, say out of 10 samples we have[6, 4] for pass and fail\n",
    "\n",
    "    total=counts.sum()\n",
    "    prob=counts/total\n",
    "    if total==0:\n",
    "        return 0.0\n",
    "\n",
    "    return 1.0 - np.sum(prob**2)\n",
    "\n",
    "#this is when we do not have the count\n",
    "\n",
    "def gini(y):\n",
    "    counts=np.bincount(y)\n",
    "    counts=np.array(counts)\n",
    "    return gini_from_counts(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c69442a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets implement the class Node\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, *, feature=None, threshold=None, gini=0.0, left=None, right=None, value=None, prob=None, n_samples=None):\n",
    "        self.feature=feature\n",
    "        self.threshold=threshold\n",
    "        self.gini=gini\n",
    "        self.right=right\n",
    "        self.left= left\n",
    "        self.value=value\n",
    "        self.prob=prob\n",
    "        self.n_samples=n_samples\n",
    "\n",
    "    def is_leaf(self):\n",
    "            return self.value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "94c99173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets write the main algo for finding the best threshold, best split and returning the gain( gain has to be max for the best split)\n",
    "\n",
    "def best_split( X, y, n_classes):\n",
    "\n",
    "   n_samples, n_features=X.shape\n",
    "   parent_counts=np.bincount(y)\n",
    "   parent_gini=gini_from_counts(parent_counts)\n",
    "   best_gain=0\n",
    "   best_feature=None\n",
    "   best_threshold=None\n",
    "\n",
    "   # for each feature calculate the cumulative class count\n",
    "\n",
    "   for feat in range(n_features):\n",
    "    col=X[:, feat]\n",
    "    order=np.argsort(col)\n",
    "    col_sorted=col[order]\n",
    "    y_sorted=y[order]\n",
    "        \n",
    "    counts_per_class=np.zeros((n_classes, n_samples), dtype=int)\n",
    "    for cls in range(n_classes):\n",
    "        counts_per_class[cls]=np.cumsum(y_sorted==cls)\n",
    "\n",
    "    total_count=parent_counts\n",
    "\n",
    "    for i in range(n_samples-1):\n",
    "        if(col_sorted[i]==col_sorted[i+1]):\n",
    "            continue\n",
    "        left_counts=counts_per_class[:, i]\n",
    "        right_counts=total_count-left_counts\n",
    "\n",
    "        left_n=i+1\n",
    "        right_n=n_samples-left_n\n",
    "\n",
    "        left_gini=gini_from_counts(left_counts)\n",
    "        right_gini=gini_from_counts(right_counts)\n",
    "\n",
    "        weighted_gini=(left_n/n_samples)*left_gini  + (right_n/n_samples)*right_gini\n",
    "        gain=parent_gini-weighted_gini\n",
    "\n",
    "        if gain>best_gain:\n",
    "            best_gain=gain\n",
    "            best_feature=feat\n",
    "            best_threshold=( col_sorted[i]+col_sorted[i+1])/2.0\n",
    "\n",
    "    return best_gain, best_feature, best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f69e55a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have the algo for getting the best split, we now need to use that to build the tree\n",
    "\n",
    "def build_tree( X, y, * , max_depth=10, min_samples_split=2, min_samples_leaf=1, min_impurity_decrease=1e-7, depth=0, n_classes=None ):\n",
    "    n_samples, n_features=X.shape\n",
    "    if n_classes is None:\n",
    "        n_classes=len(np.unique(y))\n",
    "    node_counts=np.bincount(y)\n",
    "    node_gini=gini_from_counts(node_counts)\n",
    "    majority_class=int(np.argmax(node_counts))\n",
    "    if (len(np.unique(y)) == 1) or (depth >= max_depth) or (n_samples < min_samples_split):\n",
    "        prob = node_counts / node_counts.sum()\n",
    "        return Node(value=majority_class, prob=prob, n_samples=n_samples, gini=node_gini)\n",
    "    \n",
    "    gain, feat, thresh = best_split(X, y, n_classes)\n",
    "\n",
    "    if feat is None or gain<=min_impurity_decrease:\n",
    "        prob=node_counts/node_counts.sum()\n",
    "        return Node(value=majority_class, prob=prob, n_samples=n_samples, gini=node_gini)\n",
    "    \n",
    "    left_mask=X[:, feat]<=thresh\n",
    "    right_mask=~left_mask\n",
    "\n",
    "    if left_mask.sum()<min_samples_leaf or right_mask.sum()<min_samples_leaf:\n",
    "        prob=node_counts/node_counts.sum()\n",
    "        return Node(value=majority_class, prob=prob, n_samples=n_samples, gini=node_gini)\n",
    "    \n",
    "    left_node=build_tree(X[left_mask], y[left_mask], max_depth=max_depth, min_samples_split=min_samples_split,\n",
    "                           min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease,\n",
    "                           depth=depth + 1, n_classes=n_classes)\n",
    "    right_node=build_tree(X[right_mask], y[right_mask], max_depth=max_depth, min_samples_split=min_samples_split,\n",
    "                           min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease,\n",
    "                           depth=depth + 1, n_classes=n_classes)\n",
    "    \n",
    "    return Node(feature=feat, threshold=thresh, left=left_node, right=right_node, value=None, prob=None, n_samples=n_samples, gini=node_gini)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7a7e0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "\n",
    "def predict_one(x, node):\n",
    "    while not node.is_leaf():\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            node = node.left\n",
    "        else:\n",
    "            node = node.right\n",
    "    return node.value\n",
    "\n",
    "def predict(X, node):\n",
    "    return np.array([predict_one(x, node) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1c4bd0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, depth=0):\n",
    "    prefix = \"  \" * depth\n",
    "    if node.is_leaf():\n",
    "        print(f\"{prefix}Leaf: predict={node.value}, prob={np.round(node.prob,3)}, n={node.n_samples}, gini={node.gini:.3f}\")\n",
    "    else:\n",
    "        print(f\"{prefix}Node: feat={node.feature}, thresh={node.threshold:.4f}, n={node.n_samples}, gini={node.gini:.3f}\")\n",
    "        print_tree(node.left, depth + 1)\n",
    "        print_tree(node.right, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6dacb192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: feat=0, thresh=6.0000, n=6, gini=0.500\n",
      "  Leaf: predict=0, prob=[1.], n=3, gini=0.000\n",
      "  Leaf: predict=1, prob=[0. 1.], n=3, gini=0.000\n",
      "preds: [0 0 0 1 1 1]\n",
      "accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "tree = build_tree(X, y, max_depth=3, min_samples_split=2)\n",
    "print_tree(tree)\n",
    "\n",
    "preds = predict(X, tree)\n",
    "print(\"preds:\", preds)\n",
    "print(\"accuracy:\", (preds == y).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6124512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8f553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
